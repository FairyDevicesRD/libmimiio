# mimiio_tumbler_ex3

## はじめに

### 概要

Fairy I/O Tumbler 上で、[libmimixfe](https://github.com/FairyDevicesRD/libmimixfe)と組み合わせ、録音及び信号処理された音声を入力として、リアルタイムでサーバーに送信し、リアルタイムでサーバーから認識結果を受信する libmimixfe の機能制限のないサンプルプログラムであり、N 個の同時抽出音源に対し、N 本の WebSocket 通信路を確立し、同時認識を行います。従来のサンプルプログラムを統合しました。

### 全体動作フロー

1. プログラムが開始される
2. コマンドライン引数を解析する
3. コマンドライン引数で明示的に指定された場合、リモートホストに投機的接続を実行する（バックエンドサービス種別によっては投機的接続が不能である場合があります）
4. libmimixfe により、XFERecorder を構築し、録音及び信号処理を開始する
5. libmimixfe により、発話開始が検出された時点で、本サンプルプログラムから発話イベントが発生し、本サンプルプログラムにより、ユーザーが定義したイベント処理が実行される。ユーザー定義のイベント処理は、サンプルとして、効果音が再生されたり、LED の光り方が変わるなどが実装されている。
6. Ctrl+C の入力により、全体が終了する

### コマンドライン引数

``````````.txt
usage: ./mimiio_tumbler_ex3 --host=string --port=int [options] ...
options:
  -h, --host           Host name (string)
  -p, --port           Port (int)
  -t, --token          Access token (string [=])
      --rate           Sampling rate (int [=16000])
      --channel        Number of channels (int [=1])
      --format         Audio format (string [=MIMIIO_RAW_PCM])
      --verbose        Verbose mode
      --enable-spcn    Enable speculative connection
      --lang           Language code (string [=ja])
      --services       mimi services (string [=asr])
      --help           Show help

Acceptable audio formats:
    MIMIIO_RAW_PCM
    MIMIIO_FLAC_0
    MIMIIO_FLAC_1
    MIMIIO_FLAC_2
    MIMIIO_FLAC_3
    MIMIIO_FLAC_4
    MIMIIO_FLAC_5
    MIMIIO_FLAC_6
    MIMIIO_FLAC_7
    MIMIIO_FLAC_8
    MIMIIO_FLAC_PASS_THROUGH
``````````

`--verbose` は実行段階を標準エラー出力に細かく出力するため、処理内容を理解する上で有用です。`--enable-spcn` が指定された場合、リモートホストへの投機的接続が実行されます。これは、バックエンドサービス種別が投機的接続を受け付ける場合のみ有効です。投機的接続はデフォルトでは無効です。

#### 投機的接続の実装について

何らかのタスクを実行するために、複数回の発話が必要となる場合、前の発話が終了された直後に、再度発話が行われる可能性が高いことから、本サンプルプログラムでは、前の発話が発話終了検出された直後にリモートホストへの投機的接続が行われます。この接続は、60 秒間何の発話も検出されなかった場合、タイムアウトして切断されます。切断後に発話が行われた場合は、発話開始検出と同時にリモートホストへの接続が開始されるため、ex2 のような接続のオーバーヘッドが発生します。ただし、`--services` で指定するサービス種別によっては、投機的接続を受け付けないサービスがありますので詳細は別途お問い合わせください。

## 解説

本サンプルプログラムは、発話イベントに対するユーザー定義処理を実装する形式となります。その部分について解説を行います。

### ユーザー定義発話イベント処理クラス

`mimiio_tumbler_ex3.cpp` に実装されている `MySpeechEvent` クラスが、イベント処理を実装したユーザー定義クラスです。これは、本サンプルプログラムが提供する `SpeechEvent` クラスを継承します。

``````````.cpp
class MySpeechEvent : public SpeechEvent
``````````

このクラスは、発話イベントが発生する都度並列にインスタンス化されます。このクラスのコンストラクタでは、ひとつの発話イベントに対応した動作を行うために必要な初期化を行います。本サンプルプログラムでは、効果音を鳴らしたり、LED リングの点灯状態を変化させたりするため、それらに必要なデータの構築を行っています。ここで、`MySpeechEvent` クラスは、発話が検出される都度インスタンス化されることに留意してください。コンストラクタ内で、ローカルストレージから音声ファイルをロードするような場合、発話が検出される都度、ローカルストレージにアクセスが発生するのは好ましくありません。このため、本サンプルプログラムでは、読み込み専用の static メンバ変数としてデータをロードし、無駄なディスクアクセスが発生しないようにされています。

### ユーザー定義イベントハンドラ

`MySpeechEvent` クラスでは、`SpeechEvent` クラスが提供するイベントハンドラ関数をオーバーライドしてユーザー定義処理を実装します。本サンプルプログラムは、以下の状況を検出しイベントハンドラを直列的に呼び出します。つまり、あるイベントハンドラが長い時間の掛かる処理を行うなどした場合、そこで処理が詰まることになります（そのようになっても問題がない場合もあります）。このため、イベントハンドラ内は、適宜非同期的に実装し、迅速に処理を返すようにすることがより好ましい実装となります。

#### 発話開始検出のタイミング

発話開始が検出された時点で、`MySpeechEvent::speechStartHandler(int sourceId, const std::vector<mimixfe::StreamInfo>& streamInfo)` が１回呼ばれます。これは libmimixfe における SpeechState::SpeechStart に対応しています。

本サンプルプログラムでは、発話開始検出のタイミングでは、特段の処理を行っていませんが、過去の発話イベントがある場合、その発話イベントに対して LED の制御権を解放させることを行っています。このことについては次のセクションで解説します。

#### 発話中の定期的なタイミング

libmimixfe の SpeechState::InSpeech に対応するタイミングで、`MySpeechEvent::inSpeechHandler(int sourceId, const std::vector<mimixfe::StreamInfo>& streamInfo)` が呼び出されます。

本サンプルプログラムでは、このタイミングでは何も行っていません。

#### 発話終了検出のタイミング

発話終了が検出された時点で、`MySpeechEvent::speechEndHandler(int sourceId, const std::vector<mimixfe::StreamInfo>& streamInfo)` が１回呼ばれます。これは libmimixfe の SpeechState::SpeechEnd に対応しています。

本サンプルプログラムでは、ひとつの例として、このタイミングで、音声を受け付けたことを示すために「ピコ」という効果音を再生すると同時に、LED リングの点灯状態を変化させています。音声再生も LED リングの点灯状態変更も、どちらも非同期で行っています。これは冒頭で説明した理由によります。本サンプルプログラムの LED リングの点灯制御の実装は、単純なループを使っています。もしこのループが、同期的に実行された場合、この関数が処理を返すことはなく、その結果、他のイベントハンドラが呼ばれなくなるため、破綻してしまいます。

#### リモートホストからの結果受信のタイミング

リモートホストから何らかの結果が受信された時点で、`MySpeechEvent::responseHandler(int sourceId, const std::string& response)` が都度呼ばれます。これは、libmimiio の受信コールバック関数（`rxfunc`）が呼び出されるタイミングに相当します。

本サンプルプログラムでは、ひとつの例として、このタイミングでリモートホストからの応答の JSON 文字列をを解析する処理を実装しています。認識の途中結果（`recog-in-progress`）である場合は、認識結果を画面に表示し、認識の最終結果（`recog-finished`）である場合は、最終結果を画面に表示すると同時に、何らかのユーザー定義処理を行う想定として、`sleep(3)` を行っています。この 3 秒の同期的な sleep は、何らかのユーザー定義処理に直列的に 3 秒掛かったということを想定したものとなります（UX 上 3 秒は掛かりすぎですが、動作のわかりやすさのために長めに設定しています）。ここで、最終結果を受信した場合、リモートホストからの接続は切断されるため、最終結果の受信が、最後のイベントハンドラの呼び出しとなります。これより後に呼び出されるイベントハンドラは無いため、直列的に処理を行ったとしても、全体に影響はありません。何らかのユーザー定義処理を想定した 3 秒の sleep 後、この発話イベントで LED 制御権が失われていなければ、発話終了検知のタイミングで変化させた LED の点灯状態を、デフォルトの点灯状態に戻します。最後に、この発話イベントに対する処理が完了したことを本サンプルプログラム内部に伝えるために、`finish()` 関数を呼びます。`finish()` 関数を呼ばないと、本サンプルプログラムは、この発話イベントに対する処理が終了したかどうかを知ることができないため、インスタンスをデリートすることができず、メモリを圧迫することにつながります。

ここで、例えば、認識の途中結果（`recog-in-progress`）である場合に、上記の `sleep(3)` のような同期的な長い処理を行ってしまった場合、`responseHandler` の呼び出しが詰まるため、好ましくないことに留意してください。

### 発話イベント系列の取扱

`SpeechEvent` クラスは、`SpeechEvent* prev_;` というメンバー変数を持っており、これは、ひとつ過去の発話イベントへのポインタです。すなわち、発話イベント系列は、直近の発話イベントクラスからの片方向連結リストとなっており、系列を辿ることができます。

本サンプルプログラムでは、上述のように、発話開始検出のタイミングで、このポインタをたどり、ひとつ過去の発話イベントが LED を制御しようとすることを防いでいます。これは、ひとつ過去の発話イベントが認識の最終結果の処理中（つまり、上記の `sleep(3)` の途中）だった場合、最新の発話イベントによって LED が適切に制御されているにも関わらず、ひとつ過去の発話イベントが、`sleep(3)` の終了後に、LED 制御をデフォルトに戻そうとしてしまうため、最新の発話イベントによる LED 制御と衝突し、LED 表示が乱れることを防ぐためです。

このやり方を使うと、別の応用も考えることができますが注意が必要です。例えば、ごく簡易的な対話アプリケーションを想定し、最終確定結果が「音楽を再生して」や「ニュース読み上げて」といったもので、responseHandler の `sleep(3)` に該当する部分で、音楽を再生したり、長いニュースを読み上げたりしていると想定します。次の発話が「停止して」といったもので、音楽再生やニュース読み上げを停止したい場合、このポインタを辿り、ひとつ過去の発話イベント処理クラスに対して、その実行を停止するように要求することができるということが考えられます。このような考え方には注意が必要です。それは、例を示すと、ひとつ前が対応する発話イベントではない可能性があるといったことです。すなわち、「音楽再生して」「音量上げて」「再生を停止して」という発話がなされた場合、音楽を再生している発話イベントは、２つ前の発話イベントとなるということです。つまり、発話イベントの過去系列と、アプリケーションとしての状態とは別の概念であるため、それを混同することは避けるべきであるということになります。

